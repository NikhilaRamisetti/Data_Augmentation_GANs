{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU97eS6gouJN"
      },
      "source": [
        "# Data_Augmentation_GANs\n",
        "\n",
        "This repository is a deep learning project that brings together the Discriminator (the Truth Seeker) and the Generator (the Artful Creator) to create and evaluate beautiful, yet deceiving, images. Here, we present the code snippets that define the Discriminator and Generator networks, their training process, and the visual results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PT-0Kbtf6Jj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeI0W3kwhcc5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmoLiR-ali3b"
      },
      "source": [
        "### Set the Dataset Directory and Display Information\n",
        "\n",
        "This code sets the directory containing the dataset of images, checks the number of images in the dataset, and displays the names of the first ten images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auvhaTdYf75x"
      },
      "outputs": [],
      "source": [
        "# Set the directory containing the dataset\n",
        "Image_directories = '/content/drive/My Drive/celebrities-100k/100k/'\n",
        "print(f\"Number of images in the dataset: {len(os.listdir(DATA_DIR+'/100k'))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so99CHevgaew"
      },
      "outputs": [],
      "source": [
        "# Display the first 10 files in the dataset directory\n",
        "print(f\"Sample of the dataset files: {os.listdir(Image_directories+'/100k')[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVx5DKCem0UC"
      },
      "source": [
        "### Define Image Size, Batch Size, and Normalization Statistics:\n",
        "It establishes the desired image size, batch size for training, and defines the statistical values (mean and standard deviation) for image normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DKp4-j1ciYC"
      },
      "outputs": [],
      "source": [
        "# Define image size, batch size, and image statistics for normalization\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)  # Mean and standard deviation for image normalization\n",
        "\n",
        "# Create a training dataset with transformations\n",
        "train_ds = ImageFolder(root=Image_directories,\n",
        "                       transform=T.Compose([T.Resize(image_size),\n",
        "                                            T.CenterCrop(image_size),  # Crop the center square of the image\n",
        "                                            T.ToTensor(),\n",
        "                                            T.Normalize(*stats)  # Normalize images to the range -1 to 1\n",
        "                                        ]))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx6RjLyRm5H0"
      },
      "source": [
        "### Create Training Dataset and Data Loader:\n",
        " This code creates a training dataset with image transformations like resizing and center cropping and sets up a data loader to efficiently load the data in batches for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KYxTX36ntwN"
      },
      "outputs": [],
      "source": [
        "# Create a data loader for training\n",
        "train_data = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)  # Utilize multiple CPU cores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ze1J0ZRm7uO"
      },
      "source": [
        "### Define Denormalization and Display Images:\n",
        "\n",
        "It defines functions for denormalizing image tensors and displaying a batch of images in a grid for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IULTsnSrgrDY"
      },
      "outputs": [],
      "source": [
        "# Define a function to denormalize image tensors\n",
        "def denormalization(img_tensors):\n",
        "    \"Denormalize image tensor with specified mean and std\"\n",
        "    return img_tensors * stats[1][0] + stats[0][0]\n",
        "\n",
        "# Define a function to display a batch of images\n",
        "def display_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denormalization(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWjAWtJMno7m"
      },
      "source": [
        "### Sneak Peek:\n",
        "A quick look at the generated images by the Generator even before training begins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ0QfP_Xgth9"
      },
      "outputs": [],
      "source": [
        "# Display a batch of images from the training dataset\n",
        "display_images(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFvDUUDsnA0g"
      },
      "source": [
        "### Define Device Handling Functions:\n",
        "\n",
        "These functions handle device selection (GPU or CPU) and enable the transfer of data and models to the chosen device, ensuring efficient computation on available hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnP1zevAg0HC"
      },
      "outputs": [],
      "source": [
        "# Define a function to get the default device (GPU if available, else CPU)\n",
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "# Define a function to move tensor(s) to the chosen device\n",
        "def to_device(data, device):\n",
        "    \"\"\"Transfer tensor(s) to the specified device.\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "# Create a class to wrap a dataloader and move data to a device\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Encapsulate a dataloader while transferring data to a device.\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to the device.\"\"\"\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of batches in the dataloader.\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srREb8D9hXpw"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy-fAeatnNse"
      },
      "source": [
        "## Let's build the GAN model\n",
        "\n",
        "\n",
        "### Meet the Discriminator:\n",
        "\n",
        "The code introduces the architecture of the Discriminator network, which critically evaluates generated images.\n",
        "\n",
        "The Discriminator is a neural network designed for distinguishing real images from fake ones. It comprises multiple convolutional layers with batch normalization and LeakyReLU activation functions, followed by a binary classification layer that outputs a single value (1 or 0) to determine if the input image is real or generated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSiBLbHkit2I"
      },
      "outputs": [],
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3x 64 x 64\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFqiqPiZiujo"
      },
      "outputs": [],
      "source": [
        "discriminator = to_device(discriminator, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DmCd635iw8j"
      },
      "outputs": [],
      "source": [
        "# create a tensor Batch_Size,C,H,W\n",
        "X = torch.rand(size=(1, 3, 64, 64), dtype=torch.float32, device=device)\n",
        "for layer in discriminator:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_nnKpDTncgo"
      },
      "source": [
        "### Meet the Generator:\n",
        "The code reveals the Generator's architecture, responsible for creating beautiful artwork.\n",
        "\n",
        "The Generator, on the other hand, is a neural network responsible for generating fake images that aim to fool the Discriminator. It starts with a latent vector and utilizes transposed convolutional layers with batch normalization and ReLU activation functions to progressively upscale and create realistic-looking images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWaf4-5bizUH"
      },
      "outputs": [],
      "source": [
        "latent_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLlne3wLi1oS"
      },
      "outputs": [],
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()  # output is between -1 to 1\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2POzlUii3kw"
      },
      "outputs": [],
      "source": [
        "X = torch.randn(size=(1, 128, 1, 1))\n",
        "for layer in generator:\n",
        "  X = layer(X)\n",
        "  print(layer.__class__.__name__,'output shape: \\t',X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_82imski581"
      },
      "outputs": [],
      "source": [
        "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
        "fake_images = generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWEBcpAFi9iQ"
      },
      "outputs": [],
      "source": [
        "generator = to_device(generator, device) # move generator to device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mReZ1d60nifK"
      },
      "source": [
        "\n",
        "\n",
        "## The Artful Journey\n",
        "- Training the Generator: Learn how the Artful Creator refines its skills to generate images that \"fool\" the Discriminator.\n",
        "- The Training Loop: Discover the process where art meets truth, with both the Discriminator and Generator honing their abilities.\n",
        "\n",
        "Training the Discriminator involves two key steps:\n",
        "1. Evaluating real images by computing their loss and target labels (1 for real), and\n",
        "2. Generating fake images, calculating their loss and target labels (0 for fake), and optimizing the Discriminator's weights to enhance its ability to distinguish real from fake.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx4RzNGEi_pr"
      },
      "outputs": [],
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "  # Clear discriminator gradients\n",
        "  opt_d.zero_grad()\n",
        "\n",
        "  # Pass real images through  discriminator\n",
        "  real_preds = discriminator(real_images)\n",
        "  real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "  real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "  real_score = torch.mean(real_preds).item()\n",
        "\n",
        "  # Generate fake images\n",
        "  latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "  fake_images = generator(latent)\n",
        "\n",
        "  # Pass Fake images through discriminator\n",
        "  fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "  fake_preds = discriminator(fake_images)\n",
        "  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "  fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "  # Update discriminator weights\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d.step()\n",
        "  return loss.item(), real_score, fake_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qyhxYOmolCJ"
      },
      "source": [
        "Training the Generator is about generating fake images, attempting to deceive the Discriminator (by assigning target labels of 1 for real), and updating the Generator's weights to improve its capability to generate more convincing images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SThOg1VjCL5"
      },
      "outputs": [],
      "source": [
        "def train_generator(opt_g):\n",
        "  # Clear generator gradients\n",
        "  opt_g.zero_grad()\n",
        "\n",
        "  # Generate fake images\n",
        "  latent = torch.randn(batch_size, latent_size, 1,1, device=device)\n",
        "  fake_images = generator(latent)\n",
        "\n",
        "  # Try to fool the discriminator\n",
        "  preds = discriminator(fake_images)\n",
        "  targets = torch.ones(batch_size, 1, device=device)\n",
        "  loss = F.binary_cross_entropy(preds, targets)\n",
        "\n",
        "  # Update generator\n",
        "  loss.backward()\n",
        "  opt_g.step()\n",
        "\n",
        "  return loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH9X-OJ9onCh"
      },
      "source": [
        "In the process, both the Discriminator and Generator iteratively adjust their weights to reach a balance where the Generator creates increasingly realistic images and the Discriminator gets better at distinguishing real from fake images. This adversarial training leads to the generation of high-quality images by the Generator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEG6f3Rzn2_l"
      },
      "source": [
        "## Saving Masterpieces\n",
        "- The code provides functionality to save the masterpieces generated by the Generator during training, allowing you to witness the artistic evolution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__lUXmZtjEqO"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkYudPmtjG8D"
      },
      "outputs": [],
      "source": [
        "sample_dir = 'augmented'\n",
        "os.makedirs(sample_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErjgYwvzjIno"
      },
      "outputs": [],
      "source": [
        "def save_samples(index, latent_tensors, show=True):\n",
        "  fake_images = generator(latent_tensors)\n",
        "  fake_fname = 'augmented=images-{0:0=4d}.png'.format(index)\n",
        "  save_image(denormalization(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "  print(\"Saving\", fake_fname)\n",
        "\n",
        "  if show:\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRnpkyOmjK34"
      },
      "outputs": [],
      "source": [
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SugOJEnGjTL5"
      },
      "outputs": [],
      "source": [
        "save_samples(0, fixed_latent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW31M4_LjVCo"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj-Gk9vLjWym"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, lr, start_idx = 1):\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # Losses & scores\n",
        "  losses_g = []\n",
        "  losses_d = []\n",
        "  real_scores = []\n",
        "  fake_scores = []\n",
        "\n",
        "  # Create optimizers\n",
        "  opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for real_images, _ in tqdm(train_dl):\n",
        "      # Train discriminator\n",
        "      loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "      # Train generator\n",
        "      loss_g = train_generator(opt_g)\n",
        "\n",
        "    # Record losses & scores\n",
        "    losses_g.append(loss_g)\n",
        "    losses_d.append(loss_d)\n",
        "    real_scores.append(real_score)\n",
        "    fake_scores.append(fake_score)\n",
        "\n",
        "    # Log losses & scores (last batch)\n",
        "    print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    # Save generated images\n",
        "    save_samples(epoch+start_idx, fixed_latent, show=False)\n",
        "\n",
        "  return losses_g, losses_d, real_scores, fake_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afitkF0NjY24"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lr = 0.00025\n",
        "epochs = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7eAssLXjaWM"
      },
      "outputs": [],
      "source": [
        "history = fit(epochs, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7Xe8VGsjdSd"
      },
      "outputs": [],
      "source": [
        "# Save the model checkpoints\n",
        "torch.save(generator.state_dict(), 'G.pth')\n",
        "torch.save(discriminator.state_dict(), 'D.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FHdSuEyjfQA"
      },
      "outputs": [],
      "source": [
        "losses_g, losses_d, real_scores, fake_scores = history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0NHgXhXn7Sk"
      },
      "source": [
        "\n",
        "## Visualization and Export\n",
        "- The code shows how to visualize losses and scores during training, helping you understand the training process.\n",
        "- Export the generated images and even create a video to visualize the progress of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qldj7JS1jhMg"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DUQCc3Pjhr-"
      },
      "outputs": [],
      "source": [
        "Image('./augmented/augmented=images-0001.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPX3YHPzjkQB"
      },
      "outputs": [],
      "source": [
        "Image('./augmented/augmented=images-0060.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvKgFNAOjnUY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "vid_fname = 'gans_training.avi'\n",
        "\n",
        "print(\"Starting converting images to video.\")\n",
        "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'augmented' in f]\n",
        "files.sort()\n",
        "\n",
        "print(files)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MPEG')\n",
        "out = cv2.VideoWriter(vid_fname,fourcc, 1.0, (640,480))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()\n",
        "print(\"DONE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_iQawBVjpe6"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8qGajjUjrfS"
      },
      "outputs": [],
      "source": [
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
